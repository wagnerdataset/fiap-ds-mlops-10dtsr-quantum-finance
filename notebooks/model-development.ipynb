{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a45bb792",
   "metadata": {},
   "source": [
    "# Desenvolvimento do Modelo de Classificação de Score de Crédito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c5890c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Carregar os dados diretamente do arquivo original\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "def to_float(val):\n",
    "    try:\n",
    "        return float(str(val).replace(\"_\", \"\").replace(\",\", \"\"))\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def extract_months(age_str):\n",
    "    if isinstance(age_str, str):\n",
    "        match = re.search(r\"(\\d+)\\s*Years?.*?(\\d+)?\\s*Months?\", age_str)\n",
    "        if match:\n",
    "            years = int(match.group(1))\n",
    "            months = int(match.group(2)) if match.group(2) else 0\n",
    "            return years * 12 + months\n",
    "    return np.nan\n",
    "\n",
    "def to_numeric(val):\n",
    "    try:\n",
    "        return pd.to_numeric(val)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Conversões\n",
    "cols_to_float = ['Annual_Income', 'Outstanding_Debt', 'Amount_invested_monthly', 'Monthly_Balance']\n",
    "for col in cols_to_float:\n",
    "    df[col] = df[col].apply(to_float)\n",
    "\n",
    "df['Age'] = df['Age'].apply(to_numeric)\n",
    "df['Num_of_Loan'] = df['Num_of_Loan'].apply(to_numeric)\n",
    "df['Num_of_Delayed_Payment'] = df['Num_of_Delayed_Payment'].apply(to_numeric)\n",
    "df['Credit_History_Age'] = df['Credit_History_Age'].apply(extract_months)\n",
    "\n",
    "# Preencher valores ausentes\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "cat_cols = df.select_dtypes(include=['object']).columns.drop(['Credit_Score'])\n",
    "\n",
    "for col in num_cols:\n",
    "    df[col].fillna(df[col].mean(), inplace=True)\n",
    "\n",
    "for col in cat_cols:\n",
    "    df[col].fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "# Transformar variável alvo\n",
    "label_encoder = LabelEncoder()\n",
    "df['Credit_Score_Label'] = label_encoder.fit_transform(df['Credit_Score'])\n",
    "\n",
    "# Remover colunas irrelevantes\n",
    "df.drop(columns=['ID', 'Customer_ID', 'Name', 'SSN', 'Month', 'Credit_Score'], inplace=True)\n",
    "\n",
    "# Separar X e y\n",
    "X = df.drop(columns=['Credit_Score_Label'])\n",
    "y = df['Credit_Score_Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dfda3c",
   "metadata": {},
   "source": [
    "## Modelos de Classificação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05a6b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "print(\"Decision Tree Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "print(\"Matriz de Confusão:\")\n",
    "print(confusion_matrix(y_test, y_pred_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e306bd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=500)\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "print(\"Matriz de Confusão:\")\n",
    "print(confusion_matrix(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00d7c8f",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e09ff3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"Matriz de Confusão:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ed6624",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a045d7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "gb_model.fit(X_train, y_train)\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "print(\"Gradient Boosting Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_gb))\n",
    "print(\"Matriz de Confusão:\")\n",
    "print(confusion_matrix(y_test, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffe8b54",
   "metadata": {},
   "source": [
    "### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727512f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_model = XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "print(\"XGBoost Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "print(\"Matriz de Confusão:\")\n",
    "print(confusion_matrix(y_test, y_pred_xgb))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
